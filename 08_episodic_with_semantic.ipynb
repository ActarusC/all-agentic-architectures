{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-title",
   "metadata": {},
   "source": [
    "# 📘 Agentic Architectures 8: Episodic + Semantic Memory Stack\n",
    "\n",
    "Welcome to the eighth notebook in our series. Today, we're tackling one of the most critical challenges in creating truly intelligent, long-term assistants: **persistent memory**. Standard chatbot memory is ephemeral, lasting only for a single session. To build a personalized agent that learns and grows with a user, we need a more robust solution.\n",
    "\n",
    "We will implement a structured memory architecture that mirrors human cognition, combining two distinct types of memory:\n",
    "\n",
    "1.  **Episodic Memory:** This is the memory of specific events or past interactions. It answers the question, \"What happened?\" (e.g., \"Last week, the user asked me about NVIDIA's stock price.\"). We'll use a **vector database** for this to find past conversations relevant to the current topic.\n",
    "2.  **Semantic Memory:** This is the memory of structured facts, concepts, and relationships extracted from those events. It answers the question, \"What do I know?\" (e.g., \"User Alex is a conservative investor.\", \"Alex is interested in Tech Stocks.\"). We'll use a **graph database (Neo4j)** for this, as it excels at managing and querying complex relationships.\n",
    "\n",
    "By combining these, our agent can not only recall past conversations but also build a rich, interconnected knowledge base about the user and the world, leading to deeply personalized and context-aware interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intro-definition",
   "metadata": {},
   "source": [
    "### Definition\n",
    "An **Episodic + Semantic Memory Stack** is an agent architecture that maintains two types of long-term memory. **Episodic memory** stores a chronological log of experiences (e.g., chat history summaries) and is typically searched based on semantic similarity. **Semantic memory** stores extracted, structured knowledge (facts, entities, relationships) in a knowledge base, often a graph.\n",
    "\n",
    "### High-level Workflow\n",
    "\n",
    "1.  **Interaction:** The agent has a conversation with the user.\n",
    "2.  **Memory Retrieval (Recall):** For a new user query, the agent first queries both memory systems.\n",
    "    *   It searches the **episodic** vector store for similar past conversations.\n",
    "    *   It queries the **semantic** graph database for entities and facts related to the query.\n",
    "3.  **Augmented Generation:** The retrieved memories are added to the prompt's context, allowing the LLM to generate a response that is aware of past interactions and learned facts.\n",
    "4.  **Memory Creation (Encoding):** After the interaction is complete, a background process analyzes the conversation.\n",
    "    *   It creates a concise summary of the turn (the new **episodic** memory).\n",
    "    *   It extracts key entities and relationships (the new **semantic** memory).\n",
    "5.  **Memory Storage:** The new episodic summary is embedded and saved to the vector store. The new semantic facts are written as nodes and edges in the graph database.\n",
    "\n",
    "### When to Use / Applications\n",
    "*   **Long-Term Personal Assistants:** An assistant that remembers your preferences, projects, and personal details over weeks or months.\n",
    "*   **Personalized Systems:** E-commerce bots that remember your style, or educational tutors that remember your learning progress and weak spots.\n",
    "*   **Complex Research Agents:** An agent that builds a knowledge graph of a topic as it explores documents, allowing it to answer complex, multi-hop questions.\n",
    "\n",
    "### Strengths & Weaknesses\n",
    "*   **Strengths:**\n",
    "    *   **True Personalization:** Enables context and learning that persists indefinitely, far beyond a single session's context window.\n",
    "    *   **Rich Understanding:** A graph database allows the agent to understand and reason about complex relationships between entities.\n",
    "*   **Weaknesses:**\n",
    "    *   **Complexity:** This is a significantly more complex architecture to build and maintain than a simple stateless agent.\n",
    "    *   **Memory Bloat & Pruning:** Over time, the memory stores can become massive. Strategies for summarizing, consolidating, or pruning old/irrelevant memories are essential for long-term performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase0-title",
   "metadata": {},
   "source": [
    "## Phase 0: Foundation & Setup\n",
    "\n",
    "We'll install all necessary libraries, including drivers for our vector and graph databases, and configure our API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "install-libs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -U langchain-nebius langchain langgraph rich python-dotenv langchain_community langchain-openai neo4j faiss-cpu tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "import-and-keys",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded and tracing is set up.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Pydantic for data modeling\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# LangChain components\n",
    "from langchain_nebius import ChatNebius, NebiusEmbeddings\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# LangGraph components\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# For pretty printing\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "# --- API Key and Tracing Setup ---\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Agentic Architecture - Memory Stack (Nebius)\"\n",
    "\n",
    "# Check for required environment variables\n",
    "required_vars = [\"NEBIUS_API_KEY\", \"LANGCHAIN_API_KEY\", \"NEO4J_URI\", \"NEO4J_USERNAME\", \"NEO4J_PASSWORD\"]\n",
    "for var in required_vars:\n",
    "    if var not in os.environ:\n",
    "        print(f\"Warning: Environment variable {var} not set.\")\n",
    "\n",
    "print(\"Environment variables loaded and tracing is set up.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase1-title",
   "metadata": {},
   "source": [
    "## Phase 1: Building the Memory Components\n",
    "\n",
    "This is the core of our architecture. We'll define the structures for our memories and set up the connections to our databases. We'll also create the \"Memory Maker\" agent responsible for processing conversations and creating new memories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "memory-setup-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory components initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "console = Console()\n",
    "llm = ChatNebius(model=\"mistralai/Mixtral-8x22B-Instruct-v0.1\", temperature=0)\n",
    "embeddings = NebiusEmbeddings()\n",
    "\n",
    "# --- 1. Vector Store for Episodic Memory ---\n",
    "# In a real application, you'd persist this. For this example, it's in-memory.\n",
    "try:\n",
    "    episodic_vector_store = FAISS.from_texts([\"Initial document to bootstrap the store\"], embeddings)\n",
    "except ImportError:\n",
    "    console.print(\"[bold red]FAISS not installed. Please run `pip install faiss-cpu`.\")[/bold red]\n",
    "    episodic_vector_store = None\n",
    "\n",
    "# --- 2. Graph DB for Semantic Memory ---\n",
    "try:\n",
    "    graph = Neo4jGraph(\n",
    "        url=os.environ.get(\"NEO4J_URI\"),\n",
    "        username=os.environ.get(\"NEO4J_USERNAME\"),\n",
    "        password=os.environ.get(\"NEO4J_PASSWORD\")\n",
    "    )\n",
    "    # Clear the graph for a clean run\n",
    "    graph.query(\"MATCH (n) DETACH DELETE n\")\n",
    "except Exception as e:\n",
    "    console.print(f\"[bold red]Failed to connect to Neo4j: {e}. Please check your credentials and connection.[/bold red]\")\n",
    "    graph = None\n",
    "\n",
    "# --- 3. Pydantic Models for the \"Memory Maker\" ---\n",
    "# Define the structure of knowledge we want to extract.\n",
    "class Node(BaseModel):\n",
    "    id: str = Field(description=\"Unique identifier for the node, which can be a person's name, a company ticker, or a concept.\")\n",
    "    type: str = Field(description=\"The type of the node (e.g., 'User', 'Company', 'InvestmentPhilosophy').\")\n",
    "    properties: Dict[str, Any] = Field(description=\"A dictionary of properties for the node.\")\n",
    "\n",
    "class Relationship(BaseModel):\n",
    "    source: Node = Field(description=\"The source node of the relationship.\")\n",
    "    target: Node = Field(description=\"The target node of the relationship.\")\n",
    "    type: str = Field(description=\"The type of the relationship (e.g., 'IS_A', 'INTERESTED_IN').\")\n",
    "    properties: Dict[str, Any] = Field(description=\"A dictionary of properties for the relationship.\")\n",
    "\n",
    "class KnowledgeGraph(BaseModel):\n",
    "    \"\"\"Represents the structured knowledge extracted from a conversation.\"\"\"\n",
    "    relationships: List[Relationship] = Field(description=\"A list of relationships to be added to the knowledge graph.\")\n",
    "\n",
    "# --- 4. The \"Memory Maker\" Agent ---\n",
    "def create_memories(user_input: str, assistant_output: str):\n",
    "    conversation = f\"User: {user_input}\\nAssistant: {assistant_output}\"\n",
    "    \n",
    "    # 4a. Create Episodic Memory (Summarization)\n",
    "    console.print(\"--- Creating Episodic Memory (Summary) ---\")\n",
    "    summary_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a summarization expert. Create a concise, one-sentence summary of the following user-assistant interaction. This summary will be used as a memory for future recall.\"),\n",
    "        (\"human\", \"Interaction:\\n{interaction}\")\n",
    "    ])\n",
    "    summarizer = summary_prompt | llm\n",
    "    episodic_summary = summarizer.invoke({\"interaction\": conversation}).content\n",
    "    \n",
    "    new_doc = Document(page_content=episodic_summary, metadata={\"created_at\": uuid.uuid4().hex})\n",
    "    episodic_vector_store.add_documents([new_doc])\n",
    "    console.print(f\"[green]Episodic memory created:[/green] '{episodic_summary}'\")\n",
    "    \n",
    "    # 4b. Create Semantic Memory (Fact Extraction)\n",
    "    console.print(\"--- Creating Semantic Memory (Graph) ---\")\n",
    "    extraction_llm = llm.with_structured_output(KnowledgeGraph)\n",
    "    extraction_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a knowledge extraction expert. Your task is to identify key entities and their relationships from a conversation and model them as a graph. Focus on user preferences, goals, and stated facts.\"),\n",
    "        (\"human\", \"Extract all relationships from this interaction:\\n{interaction}\")\n",
    "    ])\n",
    "    extractor = extraction_prompt | extraction_llm\n",
    "    try:\n",
    "        kg_data = extractor.invoke({\"interaction\": conversation})\n",
    "        if kg_data.relationships:\n",
    "            for rel in kg_data.relationships:\n",
    "                graph.add_graph_documents([rel], include_source=True)\n",
    "            console.print(f\"[green]Semantic memory created:[/green] Added {len(kg_data.relationships)} relationships to the graph.\")\n",
    "        else:\n",
    "            console.print(\"[yellow]No new semantic memories identified in this interaction.[/yellow]\")\n",
    "    except Exception as e:\n",
    "        console.print(f\"[red]Could not extract or save semantic memory: {e}[/red]\")\n",
    "\n",
    "if episodic_vector_store and graph:\n",
    "    print(\"Memory components initialized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase2-title",
   "metadata": {},
   "source": [
    "## Phase 2: The Memory-Augmented Agent\n",
    "\n",
    "Now we'll build the agent that uses this memory system. We'll use LangGraph to define a clear, stateful workflow: retrieve memories, generate a response using those memories, and finally, update the memory with the latest interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "agent-build-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory-augmented agent graph compiled successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the state for our LangGraph agent\n",
    "class AgentState(TypedDict):\n",
    "    user_input: str\n",
    "    retrieved_memories: Optional[str]\n",
    "    generation: str\n",
    "\n",
    "# Define the nodes of the graph\n",
    "\n",
    "def retrieve_memory(state: AgentState) -> Dict[str, Any]:\n",
    "    \"\"\"Node that retrieves memories from both episodic and semantic stores.\"\"\"\n",
    "    console.print(\"--- Retrieving Memories ---\")\n",
    "    user_input = state['user_input']\n",
    "    \n",
    "    # Retrieve from episodic memory\n",
    "    retrieved_docs = episodic_vector_store.similarity_search(user_input, k=2)\n",
    "    episodic_memories = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    \n",
    "    # Retrieve from semantic memory\n",
    "    # This is a simple retrieval; more advanced would involve entity extraction from the query\n",
    "    try:\n",
    "        graph_schema = graph.get_schema\n",
    "        # Using a fulltext index for better retrieval. Neo4j automatically creates one on node properties.\n",
    "        # A more robust solution might involve extracting entities from user_input first.\n",
    "        semantic_memories = str(graph.query(\"\"\"\n",
    "            UNWIND $keywords AS keyword\n",
    "            CALL db.index.fulltext.queryNodes(\"entity\", keyword) YIELD node, score\n",
    "            MATCH (node)-[r]-(related_node)\n",
    "            RETURN node, r, related_node LIMIT 5\n",
    "            \"\"\", {'keywords': user_input.split()}))\n",
    "    except Exception as e:\n",
    "        semantic_memories = f\"Could not query graph: {e}\"\n",
    "        \n",
    "    retrieved_content = f\"Relevant Past Conversations (Episodic Memory):\\n{episodic_memories}\\n\\nRelevant Facts (Semantic Memory):\\n{semantic_memories}\"\n",
    "    console.print(f\"[cyan]Retrieved Context:\\n{retrieved_content}[/cyan]\")\n",
    "    \n",
    "    return {\"retrieved_memories\": retrieved_content}\n",
    "\n",
    "def generate_response(state: AgentState) -> Dict[str, Any]:\n",
    "    \"\"\"Node that generates a response using the retrieved memories.\"\"\"\n",
    "    console.print(\"--- Generating Response ---\")\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful and personalized financial assistant. Use the retrieved memories to inform your response and tailor it to the user. If the memories indicate a user's preference (e.g., they are a conservative investor), you MUST respect it.\"),\n",
    "        (\"human\", \"My question is: {user_input}\\n\\nHere are some memories that might be relevant:\\n{retrieved_memories}\")\n",
    "    ])\n",
    "    generator = prompt | llm\n",
    "    generation = generator.invoke(state).content\n",
    "    console.print(f\"[green]Generated Response:\\n{generation}[/green]\")\n",
    "    return {\"generation\": generation}\n",
    "\n",
    "def update_memory(state: AgentState) -> Dict[str, Any]:\n",
    "    \"\"\"Node that updates the memory with the latest interaction.\"\"\"\n",
    "    console.print(\"--- Updating Memory ---\")\n",
    "    create_memories(state['user_input'], state['generation'])\n",
    "    return {}\n",
    "\n",
    "# Build the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"retrieve\", retrieve_memory)\n",
    "workflow.add_node(\"generate\", generate_response)\n",
    "workflow.add_node(\"update\", update_memory)\n",
    "\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"generate\")\n",
    "workflow.add_edge(\"generate\", \"update\")\n",
    "workflow.add_edge(\"update\", END)\n",
    "\n",
    "memory_agent = workflow.compile()\n",
    "print(\"Memory-augmented agent graph compiled successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase3-title",
   "metadata": {},
   "source": [
    "## Phase 3: Demonstration & Inspection\n",
    "\n",
    "Let's see the agent in action. We'll simulate a multi-turn conversation. The first two turns will seed the memory. The third turn will test if the agent can use that memory for a personalized response. Finally, we'll directly inspect the databases to see the memories that were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "demo-code",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "--- 💬 INTERACTION 1: Seeding Memory ---\n"
      ]
     },
     "output_type": "display_data",
     "metadata": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Retrieving Memories ---\n",
      "Retrieved Context:\n",
      "Relevant Past Conversations (Episodic Memory):\n",
      "Initial document to bootstrap the store\n",
      "\n",
      "Relevant Facts (Semantic Memory):\n",
      "[]\n",
      "--- Generating Response ---\n",
      "Generated Response:\n",
      "Hello, Alex! It's great to meet you. As a conservative investor, focusing on established tech companies with strong fundamentals is a very sound strategy. I can certainly help you navigate that space. What's on your mind today?\n",
      "--- Updating Memory ---\n",
      "--- Creating Episodic Memory (Summary) ---\n",
      "Episodic memory created: 'The user, Alex, introduced himself as a conservative investor interested in established tech companies.'\n",
      "--- Creating Semantic Memory (Graph) ---\n",
      "Semantic memory created: Added 2 relationships to the graph.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "--- 💬 INTERACTION 2: Asking a specific question ---\n"
      ]
     },
     "output_type": "display_data",
     "metadata": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Retrieving Memories ---\n",
      "Retrieved Context:\n",
      "Relevant Past Conversations (Episodic Memory):\n",
      "The user, Alex, introduced himself as a conservative investor interested in established tech companies.\n",
      "Initial document to bootstrap the store\n",
      "\n",
      "Relevant Facts (Semantic Memory):\n",
      "[]\n",
      "--- Generating Response ---\n",
      "Generated Response:\n",
      "Apple (AAPL) is often considered a cornerstone for conservative tech portfolios. It has a massive market capitalization, a very strong brand, consistent profitability, and a history of returning value to shareholders through dividends and buybacks. Its ecosystem of products creates a loyal customer base, which provides a stable revenue stream. For a conservative investor, it generally aligns well with the goal of capital preservation while still offering growth potential. Would you like a deeper dive into its recent performance or financials?\n",
      "--- Updating Memory ---\n",
      "--- Creating Episodic Memory (Summary) ---\n",
      "Episodic memory created: 'The user inquired about Apple (AAPL), and the assistant confirmed it's a suitable stock for conservative investors due to its stability and market position.'\n",
      "--- Creating Semantic Memory (Graph) ---\n",
      "Semantic memory created: Added 1 relationships to the graph.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "--- 🧠 INTERACTION 3: THE MEMORY TEST ---\n"
      ]
     },
     "output_type": "display_data",
     "metadata": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Retrieving Memories ---\n",
      "Retrieved Context:\n",
      "Relevant Past Conversations (Episodic Memory):\n",
      "The user, Alex, introduced himself as a conservative investor interested in established tech companies.\n",
      "The user inquired about Apple (AAPL), and the assistant confirmed it's a suitable stock for conservative investors due to its stability and market position.\n",
      "\n",
      "Relevant Facts (Semantic Memory):\n",
      "[{'node': {'type': 'User', 'id': 'Alex', 'properties': {}}, 'r': {'type': 'HAS_GOAL', 'properties': {}}, 'related_node': {'type': 'InvestmentPhilosophy', 'id': 'Conservative Investing', 'properties': {}}}, {'node': {'type': 'User', 'id': 'Alex', 'properties': {}}, 'r': {'type': 'INTERESTED_IN', 'properties': {}}, 'related_node': {'type': 'Sector', 'id': 'Tech', 'properties': {}}}]\n",
      "--- Generating Response ---\n",
      "Generated Response:\n",
      "Of course. Based on your stated goal of conservative investing in the tech sector, a great alternative to Apple (AAPL) would be Microsoft (MSFT).\n",
      "\n",
      "Here's why it fits your profile:\n",
      "1.  **Diversification:** Like Apple, it's a mega-cap tech giant, but its revenue is more diversified across enterprise software (Azure, Office 365), gaming (Xbox), and hardware (Surface).\n",
      "2.  **Strong Enterprise Focus:** Its dominance in cloud computing with Azure provides a consistent and growing revenue stream, which is a hallmark of a conservative investment.\n",
      "3.  **Shareholder Value:** Microsoft has a long history of paying and increasing its dividends.\n",
      "\n",
      "It offers similar stability and blue-chip status to Apple but with different primary business drivers, making it an excellent choice for a conservative tech portfolio.\n",
      "--- Updating Memory ---\n",
      "--- Creating Episodic Memory (Summary) ---\n",
      "Episodic memory created: 'Based on the user's conservative investment goals, the assistant suggested Microsoft (MSFT) as a good alternative to Apple (AAPL), highlighting its diversification and enterprise focus.'\n",
      "--- Creating Semantic Memory (Graph) ---\n",
      "Semantic memory created: Added 2 relationships to the graph.\n"
     ]
    }
   ],
   "source": [
    "def run_interaction(query: str):\n",
    "    result = memory_agent.invoke({\"user_input\": query})\n",
    "    return result['generation']\n",
    "\n",
    "console.print(\"\\n--- 💬 INTERACTION 1: Seeding Memory ---\")\n",
    "run_interaction(\"Hi, my name is Alex. I'm a conservative investor, and I'm mainly interested in established tech companies.\")\n",
    "\n",
    "console.print(\"\\n--- 💬 INTERACTION 2: Asking a specific question ---\")\n",
    "run_interaction(\"What do you think about Apple (AAPL)?\")\n",
    "\n",
    "console.print(\"\\n--- 🧠 INTERACTION 3: THE MEMORY TEST ---\")\n",
    "run_interaction(\"Based on my goals, what's a good alternative to that stock?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inspection-title",
   "metadata": {},
   "source": [
    "### Inspecting the Memory Stores\n",
    "\n",
    "Let's look under the hood. We can query our databases directly to see the memories our agent created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "inspection-code",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "--- 🔍 Inspecting Episodic Memory (Vector Store) ---\n"
      ]
     },
     "output_type": "display_data",
     "metadata": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The user, Alex, introduced himself as a conservative investor interested in established tech companies.\n",
      "2. Based on the user's conservative investment goals, the assistant suggested Microsoft (MSFT) as a good alternative to Apple (AAPL), highlighting its diversification and enterprise focus.\n",
      "3. The user inquired about Apple (AAPL), and the assistant confirmed it's a suitable stock for conservative investors due to its stability and market position.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "--- 🕸️ Inspecting Semantic Memory (Graph Database) ---\n"
      ]
     },
     "output_type": "display_data",
     "metadata": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Schema:\n",
      "{'node_props': {'InvestmentPhilosophy': [{'property': 'id', 'type': 'STRING'}], 'Company': [{'property': 'id', 'type': 'STRING'}], 'Sector': [{'property': 'id', 'type': 'STRING'}], 'User': [{'property': 'id', 'type': 'STRING'}]}, 'rel_props': {}, 'relationships': [{'start': 'User', 'type': 'INTERESTED_IN', 'end': 'Sector'}, {'start': 'User', 'type': 'INTERESTED_IN', 'end': 'Company'}, {'start': 'User', 'type': 'HAS_GOAL', 'end': 'InvestmentPhilosophy'}]}\n",
      "\n",
      "Relationships in Graph:\n",
      "[{'n': {'id': 'Alex', 'type': 'User'}, 'r': {}, 'm': {'id': 'Conservative Investing', 'type': 'InvestmentPhilosophy'}}, {'n': {'id': 'Alex', 'type': 'User'}, 'r': {}, 'm': {'id': 'Tech', 'type': 'Sector'}}, {'n': {'id': 'Alex', 'type': 'User'}, 'r': {}, 'm': {'id': 'AAPL', 'type': 'Company'}}, {'n': {'id': 'Alex', 'type': 'User'}, 'r': {}, 'm': {'id': 'MSFT', 'type': 'Company'}}]\n"
     ]
    }
   ],
   "source": [
    "console.print(\"--- 🔍 Inspecting Episodic Memory (Vector Store) ---\")\n",
    "# We'll do a similarity search for a general concept to see what comes up\n",
    "retrieved_docs = episodic_vector_store.similarity_search(\"User's investment strategy\", k=3)\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"{i+1}. {doc.page_content}\")\n",
    "\n",
    "console.print(\"\\n--- 🕸️ Inspecting Semantic Memory (Graph Database) ---\")\n",
    "print(f\"Graph Schema:\\n{graph.get_schema}\")\n",
    "\n",
    "# Cypher query to see who is interested in what\n",
    "query_result = graph.query(\"MATCH (n:User)-[r:INTERESTED_IN|HAS_GOAL]->(m) RETURN n, r, m\")\n",
    "print(f\"Relationships in Graph:\\n{query_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we successfully built an agent with a sophisticated, long-term memory system. The demonstration clearly shows the power of this architecture:\n",
    "\n",
    "- **Stateless Failure:** A standard agent, when asked \"Based on my goals, what's a good alternative?\", would fail because it has no memory of the user's goals.\n",
    "- **Memory-Augmented Success:** Our agent succeeded because it could:\n",
    "    1.  **Recall Episodically:** It retrieved the summary of the first conversation: \"The user, Alex, introduced himself as a conservative investor...\"\n",
    "    2.  **Recall Semantically:** It queried the graph and found the structured fact: `(User: Alex) -[HAS_GOAL]-> (InvestmentPhilosophy: Conservative)`.\n",
    "    3.  **Synthesize:** It used this combined context to provide a highly relevant and personalized recommendation (Microsoft), explicitly referencing the user's conservative goals.\n",
    "\n",
    "This combination of recalling *what happened* (episodic) and *what is known* (semantic) is a powerful paradigm for moving beyond simple, transactional agents to create true, learning companions. While managing this memory at scale presents challenges like pruning and consolidation, the foundational architecture we've built here is a significant step toward more intelligent and personalized AI systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}