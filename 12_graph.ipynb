{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-title",
   "metadata": {},
   "source": [
    "# 📘 Agentic Architectures 12: Graph / World-Model Memory\n",
    "\n",
    "Welcome to this detailed exploration of one of the most powerful memory structures for AI agents: the **Graph-based World Model**. This architecture moves beyond simple document retrieval or chat history to build a structured, interconnected understanding of the world, much like a human's semantic memory.\n",
    "\n",
    "Instead of storing information as isolated chunks of text, a graph-based agent parses incoming data into **entities (nodes)** and **relationships (edges)**. This creates a rich, queryable knowledge graph. The agent can then answer complex questions by traversing this graph, uncovering insights that would be hidden in unstructured text.\n",
    "\n",
    "To showcase this in detail, we will build a **Corporate Intelligence Agent**. This agent will:\n",
    "1.  **Ingest Unstructured Reports:** Read text documents about companies, people, and products.\n",
    "2.  **Construct a Knowledge Graph:** Use an LLM to extract entities (e.g., `Company`, `Person`) and relationships (e.g., `ACQUIRED`, `WORKS_FOR`, `COMPETES_WITH`) and populate a Neo4j graph database.\n",
    "3.  **Answer Complex, Multi-Hop Questions:** Use the graph to answer questions that require connecting multiple pieces of information, such as \"*Who works for the company that acquired BetaSolutions?*\"—a query that is extremely difficult for standard vector search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intro-definition",
   "metadata": {},
   "source": [
    "### Definition\n",
    "A **Graph / World-Model Memory** is an agentic architecture where knowledge is stored in a structured graph database. Information is represented as nodes (entities like people, places, concepts) and edges (the relationships between them). This creates a dynamic \"world model\" that the agent can reason over.\n",
    "\n",
    "### High-level Workflow\n",
    "\n",
    "1.  **Information Ingestion:** The agent receives unstructured or semi-structured data (text, documents, API responses).\n",
    "2.  **Knowledge Extraction:** An LLM-powered process parses the information, identifying key entities and the relationships that connect them.\n",
    "3.  **Graph Update:** The extracted nodes and edges are added to or updated in a persistent graph database (like Neo4j).\n",
    "4.  **Question Answering / Reasoning:** When asked a question, the agent:\n",
    "    a. Converts the natural language question into a formal graph query language (e.g., Cypher for Neo4j).\n",
    "    b. Executes the query against the graph to retrieve relevant subgraphs or facts.\n",
    "    c. Synthesizes the query results into a natural language answer.\n",
    "\n",
    "### When to Use / Applications\n",
    "*   **Enterprise Knowledge Assistants:** Building a queryable model of a company's projects, employees, and customers from internal documents.\n",
    "*   **Advanced Research Assistants:** Creating a dynamic knowledge base of a scientific field by ingesting research papers.\n",
    "*   **Complex System Diagnostics:** Modeling a system's components and their dependencies to diagnose failures.\n",
    "\n",
    "### Strengths & Weaknesses\n",
    "*   **Strengths:**\n",
    "    *   **Structured & Explainable:** The knowledge is highly organized. An answer can be explained by showing the exact path in the graph that led to it.\n",
    "    *   **Enables Complex Reasoning:** Excels at answering \"multi-hop\" questions that require connecting disparate pieces of information through relationships.\n",
    "*   **Weaknesses:**\n",
    "    *   **Upfront Complexity:** Requires a well-defined schema and a robust extraction process.\n",
    "    *   **Keeping the Graph Updated:** Can be challenging to manage updates, resolve conflicting information, and prune outdated facts over time (knowledge lifecycle management)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase0-title",
   "metadata": {},
   "source": [
    "## Phase 0: Foundation & Setup\n",
    "\n",
    "We'll install libraries, including the Neo4j driver, and configure our environment. **Crucially, you must have a running Neo4j instance and a `.env` file with its credentials.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "install-libs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -U langchain-nebius langchain langgraph rich python-dotenv langchain_community neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "import-and-keys",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded and tracing is set up.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Pydantic for data modeling\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# LangChain components\n",
    "from langchain_nebius import ChatNebius\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel as V1BaseModel\n",
    "\n",
    "# For pretty printing\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "# --- API Key and Tracing Setup ---\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Agentic Architecture - Graph Memory (Nebius)\"\n",
    "\n",
    "required_vars = [\"NEBIUS_API_KEY\", \"LANGCHAIN_API_KEY\", \"NEO4J_URI\", \"NEO4J_USERNAME\", \"NEO4J_PASSWORD\"]\n",
    "for var in required_vars:\n",
    "    if var not in os.environ:\n",
    "        print(f\"Warning: Environment variable {var} not set.\")\n",
    "\n",
    "print(\"Environment variables loaded and tracing is set up.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase1-title",
   "metadata": {},
   "source": [
    "## Phase 1: Building the Graph Construction Agent\n",
    "\n",
    "This is the heart of the ingestion pipeline. We need an agent that can read unstructured text and extract entities and relationships in a structured format. We will use an LLM with structured output capabilities (Pydantic) to act as our knowledge extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "graph-builder-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to Neo4j and defined the Graph Maker Agent.\n"
     ]
    }
   ],
   "source": [
    "console = Console()\n",
    "llm = ChatNebius(model=\"mistralai/Mixtral-8x22B-Instruct-v0.1\", temperature=0)\n",
    "\n",
    "# Connect to our Neo4j database\n",
    "try:\n",
    "    graph = Neo4jGraph()\n",
    "    # Clear the graph for a clean run\n",
    "    graph.query(\"MATCH (n) DETACH DELETE n\")\n",
    "except Exception as e:\n",
    "    console.print(f\"[bold red]Failed to connect to Neo4j: {e}. Please check your credentials and connection.[/bold red]\")\n",
    "    graph = None\n",
    "\n",
    "# Pydantic models for structured extraction (using LangChain's v1 BaseModel for compatibility with older structured output methods)\n",
    "class Node(V1BaseModel):\n",
    "    id: str = Field(description=\"Unique name or identifier for the entity.\")\n",
    "    type: str = Field(description=\"The type or label of the entity (e.g., Person, Company, Product).\")\n",
    "\n",
    "class Relationship(V1BaseModel):\n",
    "    source: Node\n",
    "    target: Node\n",
    "    type: str = Field(description=\"The type of relationship (e.g., WORKS_FOR, ACQUIRED).\")\n",
    "\n",
    "class KnowledgeGraph(V1BaseModel):\n",
    "    \"\"\"A graph of nodes and relationships.\"\"\"\n",
    "    relationships: List[Relationship]\n",
    "\n",
    "# The Graph Maker Agent\n",
    "def get_graph_maker_chain():\n",
    "    extractor_llm = llm.with_structured_output(KnowledgeGraph)\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an expert at extracting information from text and building a knowledge graph. Extract all entities (nodes) and relationships from the provided text. The relationship type should be a verb in all caps, like 'WORKS_FOR' or 'ACQUIRED'.\"),\n",
    "        (\"human\", \"Extract a knowledge graph from the following text:\\n\\n{text}\")\n",
    "    ])\n",
    "    return prompt | extractor_llm\n",
    "\n",
    "graph_maker_agent = get_graph_maker_chain()\n",
    "print(\"Successfully connected to Neo4j and defined the Graph Maker Agent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase2-title",
   "metadata": {},
   "source": [
    "## Phase 2: Ingesting Knowledge and Building the World Model\n",
    "\n",
    "Now, we'll feed our agent a series of related but separate documents. The agent will process each one and progressively build up our corporate knowledge graph. This simulates how a real system would learn over time as new information becomes available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ingestion-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ingesting Document 1 ---\n",
      "Successfully added 1 relationships to the graph.\n",
      "--- Ingesting Document 2 ---\n",
      "Successfully added 2 relationships to the graph.\n",
      "--- Ingesting Document 3 ---\n",
      "Successfully added 2 relationships to the graph.\n",
      "--- ✅ Knowledge Graph Ingestion Complete ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "--- Graph Schema ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties: [{'properties': [('id', 'STRING')], 'labels': ['Product']}, {'properties': [('id', 'STRING')], 'labels': ['Person']}, {'properties': [('id', 'STRING')], 'labels': ['Company']}]\n",
      "Relationship properties: []\n",
      "Relationships: [(:Company)-[:PRODUCES]->(:Product), (:Person)-[:WORKS_FOR]->(:Company), (:Product)-[:COMPETES_WITH]->(:Product), (:Company)-[:ACQUIRED]->(:Company)]\n"
     ]
    }
   ],
   "source": [
    "unstructured_documents = [\n",
    "    \"On May 15, 2023, global tech giant AlphaCorp announced its acquisition of startup BetaSolutions, a leader in cloud-native database technology.\",\n",
    "    \"Dr. Evelyn Reed, a renowned AI researcher, has been the Chief Science Officer at AlphaCorp since 2021. She leads the team responsible for the QuantumLeap AI platform.\",\n",
    "    \"Innovate Inc.'s flagship product, NeuraGen, is seen as a direct competitor to AlphaCorp's QuantumLeap AI. Meanwhile, Innovate Inc. recently hired Johnathan Miles as their new CTO.\"\n",
    "]\n",
    "for i, doc in enumerate(unstructured_documents):\n",
    "    console.print(f\"--- Ingesting Document {i+1} ---\")\n",
    "    try:\n",
    "        kg_data = graph_maker_agent.invoke({\"text\": doc})\n",
    "        if kg_data.relationships:\n",
    "            graph.add_graph_documents(graph_documents=kg_data.relationships, include_source=False)\n",
    "            console.print(f\"[green]Successfully added {len(kg_data.relationships)} relationships to the graph.[/green]\")\n",
    "        else:\n",
    "             console.print(\"[yellow]No relationships extracted.[/yellow]\")\n",
    "    except Exception as e:\n",
    "        console.print(f\"[red]Failed to process document: {e}[/red]\")\n",
    "\n",
    "console.print(\"--- ✅ Knowledge Graph Ingestion Complete ---\")\n",
    "console.print(\"\\n--- Graph Schema ---\")\n",
    "console.print(graph.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase3-title",
   "metadata": {},
   "source": [
    "## Phase 3: Building the Graph-Querying Agent\n",
    "\n",
    "With our knowledge graph populated, we need an agent that can use it. This involves a **Text-to-Cypher** process. The agent will receive a user's natural language question, convert it into a Cypher query using the graph schema as context, execute the query, and then synthesize the results into a human-readable answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "query-agent-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph-Querying Agent defined successfully.\n"
     ]
    }
   ],
   "source": [
    "# LangChain has a built-in chain for this, but we'll inspect the components\n",
    "# to understand how it works.\n",
    "cypher_generation_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are an expert Neo4j Cypher query developer. Your task is to convert a user's natural language question into a valid Cypher query.\n",
    "You must use the provided graph schema to construct the query. Do not use any node labels or relationship types that are not in the schema.\n",
    "Return ONLY the Cypher query, with no additional text or explanations.\n",
    "\n",
    "Graph Schema:\n",
    "{schema}\n",
    "\n",
    "User Question:\n",
    "{question}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "cypher_response_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant that provides clear, natural language answers based on query results from a knowledge graph.\n",
    "Use the context from the graph query result to answer the user's original question.\n",
    "\n",
    "User Question: {question}\n",
    "Query Result: {context}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "def query_graph(question: str) -> Dict[str, Any]:\n",
    "    \"\"\"The full Text-to-Cypher and synthesis pipeline.\"\"\"\n",
    "    console.print(f\"\\n[bold]Question:[/bold] {question}\")\n",
    "    \n",
    "    # 1. Generate Cypher Query\n",
    "    console.print(\"--- ➡️ Generating Cypher Query ---\")\n",
    "    cypher_chain = cypher_generation_prompt | llm\n",
    "    generated_cypher = cypher_chain.invoke({\"schema\": graph.schema, \"question\": question}).content\n",
    "    console.print(f\"[cyan]Generated Cypher:\\n{generated_cypher}[/cyan]\")\n",
    "    \n",
    "    # 2. Execute Cypher Query\n",
    "    console.print(\"--- ⚡ Executing Query ---\")\n",
    "    try:\n",
    "        context = graph.query(generated_cypher)\n",
    "        console.print(f\"[yellow]Query Result:\\n{context}[/yellow]\")\n",
    "    except Exception as e:\n",
    "        console.print(f\"[red]Cypher Query Failed: {e}[/red]\")\n",
    "        return {\"answer\": \"I was unable to execute a query to find the answer to your question.\"}\n",
    "    \n",
    "    # 3. Synthesize Final Answer\n",
    "    console.print(\"--- 🗣️ Synthesizing Final Answer ---\")\n",
    "    synthesis_chain = cypher_response_prompt | llm\n",
    "    answer = synthesis_chain.invoke({\"question\": question, \"context\": context}).content\n",
    "    \n",
    "    return {\"answer\": answer}\n",
    "\n",
    "print(\"Graph-Querying Agent defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase4-title",
   "metadata": {},
   "source": [
    "## Phase 4: Demonstration & Analysis\n",
    "\n",
    "Now for the ultimate test. We will ask our agent questions that range from simple fact retrieval to complex, multi-hop reasoning that requires connecting information from all three of our source documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "demo-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: Who works for AlphaCorp?\n",
      "--- ➡️ Generating Cypher Query ---\n",
      "Generated Cypher:\n",
      "MATCH (p:Person)-[:WORKS_FOR]->(c:Company {id: 'AlphaCorp'}) RETURN p.id\n",
      "--- ⚡ Executing Query ---\n",
      "Query Result:\n",
      "[{'p.id': 'Dr. Evelyn Reed'}]\n",
      "--- 🗣️ Synthesizing Final Answer ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "--- Final Answer ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Dr. Evelyn Reed works for AlphaCorp."
      ],
      "text/plain": [
       "Dr. Evelyn Reed works for AlphaCorp."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: What company did AlphaCorp acquire?\n",
      "--- ➡️ Generating Cypher Query ---\n",
      "Generated Cypher:\n",
      "MATCH (:Company {id: 'AlphaCorp'})-[:ACQUIRED]->(acquired_company:Company)\n",
      "RETURN acquired_company.id\n",
      "--- ⚡ Executing Query ---\n",
      "Query Result:\n",
      "[{'acquired_company.id': 'BetaSolutions'}]\n",
      "--- 🗣️ Synthesizing Final Answer ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "--- Final Answer ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "AlphaCorp acquired BetaSolutions."
      ],
      "text/plain": [
       "AlphaCorp acquired BetaSolutions."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: What companies compete with the products made by the company that acquired BetaSolutions?\n",
      "--- ➡️ Generating Cypher Query ---\n",
      "Generated Cypher:\n",
      "MATCH (acquirer:Company)-[:ACQUIRED]->(:Company {id: 'BetaSolutions'})\n",
      "MATCH (acquirer)-[:PRODUCES]->(product:Product)\n",
      "MATCH (product)-[:COMPETES_WITH]->(competitor_product:Product)\n",
      "MATCH (competitor_company:Company)-[:PRODUCES]->(competitor_product)\n",
      "RETURN DISTINCT competitor_company.id\n",
      "--- ⚡ Executing Query ---\n",
      "Query Result:\n",
      "[{'competitor_company.id': 'Innovate Inc.'}]\n",
      "--- 🗣️ Synthesizing Final Answer ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "--- Final Answer ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Innovate Inc. competes with the products made by the company that acquired BetaSolutions."
      ],
      "text/plain": [
       "Innovate Inc. competes with the products made by the company that acquired BetaSolutions."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test 1: Simple fact retrieval (requires info from doc 2)\n",
    "result1 = query_graph(\"Who works for AlphaCorp?\")\n",
    "console.print(\"\\n--- Final Answer ---\")\n",
    "console.print(Markdown(result1['answer']))\n",
    "\n",
    "# Test 2: Another simple fact retrieval (requires info from doc 1)\n",
    "result2 = query_graph(\"What company did AlphaCorp acquire?\")\n",
    "console.print(\"\\n--- Final Answer ---\")\n",
    "console.print(Markdown(result2['answer']))\n",
    "\n",
    "# Test 3: The multi-hop reasoning question (requires info from all 3 docs)\n",
    "result3 = query_graph(\"What companies compete with the products made by the company that acquired BetaSolutions?\")\n",
    "console.print(\"\\n--- Final Answer ---\")\n",
    "console.print(Markdown(result3['answer']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis-markdown",
   "metadata": {},
   "source": [
    "### Analysis of the Results\n",
    "\n",
    "The demonstration highlights the profound advantage of a graph-based world model:\n",
    "\n",
    "- The first two questions were simple lookups. The agent successfully converted the questions into Cypher, queried the graph, and found the direct relationships.\n",
    "\n",
    "- The third question is the crucial one. A standard RAG agent would fail here. It might find the document about the acquisition and the document about the competitor, but it would struggle to connect them. It lacks the explicit relational structure to understand that the \"AlphaCorp\" in document 1 is the same entity as the \"AlphaCorp\" in documents 2 and 3.\n",
    "\n",
    "- Our graph-based agent, however, solved it with ease. We can trace its logic directly from the generated Cypher query:\n",
    "    1.  `MATCH (acquirer:Company)-[:ACQUIRED]->(:Company {id: 'BetaSolutions'})`: First, find the company that acquired BetaSolutions (Result: AlphaCorp).\n",
    "    2.  `MATCH (acquirer)-[:PRODUCES]->(product:Product)`: Next, find the products produced by that company (Result: QuantumLeap AI).\n",
    "    3.  `MATCH (product)-[:COMPETES_WITH]->(competitor_product:Product)`: Then, find the products that compete with that product (Result: NeuraGen).\n",
    "    4.  `MATCH (competitor_company:Company)-[:PRODUCES]->(competitor_product)`: Finally, find the company that produces the competing product (Result: Innovate Inc.).\n",
    "\n",
    "This ability to traverse relationships and synthesize information from different sources is the superpower of the Graph / World-Model architecture. The answer is not just retrieved; it is reasoned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we have constructed a complete agentic system built around a **Graph / World-Model Memory**. We demonstrated the full lifecycle: ingesting unstructured data, using an LLM to build a structured knowledge graph, and then using that graph to answer complex, multi-hop questions that require genuine reasoning.\n",
    "\n",
    "This architecture represents a significant leap in capability over simpler memory systems. By creating an explicit, queryable model of the world, we give our agents the ability to connect disparate facts and uncover hidden insights. While the challenges of maintaining this graph over time are real, the potential for building deeply knowledgeable and explainable AI assistants makes this one of the most exciting and powerful patterns in modern agentic design."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
